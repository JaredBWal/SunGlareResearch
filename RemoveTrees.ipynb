{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description:\n",
    "Testing Environment for removing trees from a panoramic image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 3/3 [06:43<00:00, 134.34s/it]\n",
      "Loading pipeline components...: 100%|██████████| 6/6 [06:12<00:00, 62.14s/it] \n"
     ]
    }
   ],
   "source": [
    "from transformers import SegformerFeatureExtractor, SegformerForSemanticSegmentation\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from diffusers import AutoPipelineForInpainting\n",
    "from diffusers.utils import load_image, make_image_grid\n",
    "\n",
    "\n",
    "# testing:\n",
    "def main():\n",
    "    \n",
    "    pipeline = AutoPipelineForInpainting.from_pretrained(\n",
    "    \"kandinsky-community/kandinsky-2-2-decoder-inpaint\", torch_dtype=torch.float16\n",
    "    )\n",
    "    pipeline.enable_model_cpu_offload()\n",
    "    \n",
    "    ##### test out gen ai method\n",
    "    \n",
    "    # init_image = load_image(\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint.png\")\n",
    "    # mask_image = load_image(\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/inpaint_mask.png\")\n",
    "    \n",
    "    # prompt = \"a black cat with glowing eyes, cute, adorable, disney, pixar, highly detailed, 8k\"\n",
    "    # negative_prompt = \"bad anatomy, deformed, ugly, disfigured\"\n",
    "    # image = pipeline(prompt=prompt, negative_prompt=negative_prompt, image=init_image, mask_image=mask_image).images[0]\n",
    "    # make_image_grid([init_image, mask_image, image], rows=1, cols=3)\n",
    "    \n",
    "    ################\n",
    "    \n",
    "    image_path = \"data/panoramic_imgs/_HveufZbNlDXqHIEDRNFzg.jpg\" \n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    feature_extractor = SegformerFeatureExtractor.from_pretrained(\"nvidia/segformer-b5-finetuned-cityscapes-1024-1024\")\n",
    "    model = SegformerForSemanticSegmentation.from_pretrained(\"nvidia/segformer-b5-finetuned-cityscapes-1024-1024\")\n",
    "\n",
    "    inputs = feature_extractor(images=image, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "\n",
    "    print(\"about to convert logits to class predictions\")\n",
    "    # convert logits to class predictions\n",
    "    predicted_class = torch.argmax(logits, dim=1)  # shape (batch_size, height/4, width/4)\n",
    "\n",
    "    # upsample to match input image size\n",
    "    predicted_class = torch.nn.functional.interpolate(\n",
    "        predicted_class.unsqueeze(1).float(),  # Add channel dimension\n",
    "        size=image.size[::-1],  # Match input image dimensions (height, width)\n",
    "        mode=\"nearest\"\n",
    "    ).squeeze(1).to(torch.int32)\n",
    "\n",
    "    print(\"about to visualize\")\n",
    "    # visualize\n",
    "    segmentation_map = predicted_class[0].cpu().numpy()\n",
    "    \n",
    "    cv_image = cv2.imread(\"data/panoramic_imgs/_HveufZbNlDXqHIEDRNFzg.jpg\")\n",
    "    class_8_mask = (segmentation_map == 8).astype(np.uint8) * 255\n",
    "    cv2.imwrite('tree_mask.jpg', class_8_mask)\n",
    "    cv_mask = cv2.imread('tree_mask.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    inpainted_image = cv2.inpaint(cv_image, cv_mask, inpaintRadius=3, flags=cv2.INPAINT_TELEA)\n",
    "    \n",
    "    inpainted_image[class_8_mask == 255] = sky_resized[class_8_mask == 255]\n",
    "    inpainted_image = cv2.cvtColor(inpainted_image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    \n",
    "    fig, ax = plt.subplots(1, 3, figsize=(20, 5))\n",
    "    \n",
    "    # Original image\n",
    "    ax[0].imshow(image)\n",
    "    ax[0].set_title(\"Original Image\")\n",
    "    ax[0].axis(\"off\")\n",
    "    \n",
    "    # Mask\n",
    "    ax[1].imshow(class_8_mask, cmap='gray')\n",
    "    ax[1].set_title(\"Tree Mask\")\n",
    "    ax[1].axis(\"off\")\n",
    "\n",
    "    # Inpainted image\n",
    "    ax[2].imshow(inpainted_image)\n",
    "    ax[2].set_title(\"Inpainted Image\")\n",
    "    ax[2].axis(\"off\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # # save the image\n",
    "    # plt.imsave(\"data\\image_processing\\\\test_segmented_image.jpg\", segmentation_map, cmap=cmap, vmin=0, vmax=num_classes - 1)\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO Remove the trees (class 8) and replace them with either sky (class 10) or buildings (class 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Panoramic image examples can be found in the data/panoramic_imgs folder\n",
    "\n",
    "# the idea is we call this function and pass in an image, and it will return the same image, but with the trees removed\n",
    "# we can either remove trees from the original image, or remove them from the segmentation map\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
