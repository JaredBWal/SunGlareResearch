{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description:\n",
    "\n",
    "- script for processing un-automated datasets to compare with the tool (such as car crashes and traffic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading graph for the specified place...\n",
      "                                            geometry  bbox_west  bbox_south  \\\n",
      "0  POLYGON ((-77.53259 38.30853, -77.53184 38.308...  -77.53259   38.270151   \n",
      "\n",
      "   bbox_east  bbox_north   place_id  osm_type   osm_id        lat       lon  \\\n",
      "0 -77.446793   38.326638  320417545  relation  1633328  38.303184 -77.46054   \n",
      "\n",
      "      class            type  place_rank  importance addresstype  \\\n",
      "0  boundary  administrative          12    0.555167        city   \n",
      "\n",
      "             name                             display_name  \n",
      "0  Fredericksburg  Fredericksburg, Virginia, United States  \n",
      "Reading crash dataset...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/fredericksburg/features (1).csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 66\u001b[0m\n\u001b[0;32m     61\u001b[0m     output_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msimple_place_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/car_crashes_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msimple_place_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     62\u001b[0m     filter_crashes_within_area(data_file, place_name, output_file)\n\u001b[1;32m---> 66\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 62\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     60\u001b[0m data_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msimple_place_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/features (1).csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     61\u001b[0m output_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msimple_place_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/car_crashes_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msimple_place_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 62\u001b[0m \u001b[43mfilter_crashes_within_area\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplace_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 28\u001b[0m, in \u001b[0;36mfilter_crashes_within_area\u001b[1;34m(data_file, place_name, output_file)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# 2. Read the crash dataset\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReading crash dataset...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 28\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Check if the required columns (LAT and LON) exist\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLAT\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLON\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns:\n",
      "File \u001b[1;32mc:\\Users\\Jared\\OneDrive\\Desktop\\UrbanRep\\.venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Jared\\OneDrive\\Desktop\\UrbanRep\\.venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\Jared\\OneDrive\\Desktop\\UrbanRep\\.venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Jared\\OneDrive\\Desktop\\UrbanRep\\.venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\Jared\\OneDrive\\Desktop\\UrbanRep\\.venv\\lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/fredericksburg/features (1).csv'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import osmnx as ox\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point, Polygon\n",
    "import geopandas as gpd\n",
    "import os\n",
    "\n",
    "def filter_crashes_within_area(data_file, place_name, output_file):\n",
    "    \"\"\"\n",
    "    Reads crash data and saves entries located within the bounding area defined by osmnx's graph_from_place.\n",
    "\n",
    "    Parameters:\n",
    "        data_file (str): Path to the CSV file containing crash data.\n",
    "        place_name (str): The place name to create the bounding area (e.g., \"Fredericksburg, VA, USA\").\n",
    "        output_file (str): Path to save the filtered data.\n",
    "\n",
    "    Returns:\n",
    "        None: Saves the filtered data to a new CSV file.\n",
    "    \"\"\"\n",
    "\n",
    "      # 1. Load the graph and convert it into a GeoDataFrame (bounding area)\n",
    "    print(\"Loading graph for the specified place...\")\n",
    "    graph = ox.graph_from_place(place_name, network_type=\"drive\")\n",
    "    gdf_boundary = ox.geocode_to_gdf(place_name)\n",
    "    print(gdf_boundary)\n",
    "    \n",
    "    # 2. Read the crash dataset\n",
    "    print(\"Reading crash dataset...\")\n",
    "    df = pd.read_csv(data_file)\n",
    "\n",
    "    # Check if the required columns (LAT and LON) exist\n",
    "    if 'LAT' not in df.columns or 'LON' not in df.columns:\n",
    "        print(\"Error: LAT and LON columns are missing in the dataset.\")\n",
    "        return\n",
    "\n",
    "    # 3. Convert crash data to GeoDataFrame using LAT and LON\n",
    "    print(\"Converting crash data to GeoDataFrame...\")\n",
    "    df['geometry'] = df.apply(lambda row: Point(row['LON'], row['LAT']), axis=1)\n",
    "    gdf_crashes = gpd.GeoDataFrame(df, geometry='geometry', crs=\"EPSG:4326\")\n",
    "\n",
    "    # 4. Filter crashes that fall within the bounding area\n",
    "    print(\"Filtering crashes within the area...\")\n",
    "    gdf_crashes_within = gdf_crashes[gdf_crashes.within(gdf_boundary.unary_union)]\n",
    "\n",
    "    # 5. Save the filtered crashes to a new CSV file\n",
    "    print(f\"Saving filtered crashes to {output_file}...\")\n",
    "    gdf_crashes_within.drop(columns=['geometry'], inplace=True)  # Remove geometry column before saving\n",
    "    gdf_crashes_within.to_csv(output_file, index=False)\n",
    "\n",
    "    print(\"Process complete. Filtered data saved successfully.\")\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    place_name = \"fredericksburg, VA, USA\"\n",
    "    simple_place_name = place_name.split(\",\")[0]\n",
    "\n",
    "    os.makedirs(f\"../data/{simple_place_name}\", exist_ok=True)\n",
    "\n",
    "    data_file = f\"../data/{simple_place_name}/features (1).csv\"\n",
    "    output_file = f\"../data/{simple_place_name}/car_crashes_{simple_place_name}.csv\"\n",
    "    filter_crashes_within_area(data_file, place_name, output_file)\n",
    "\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing Crashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import BallTree\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "def find_nearest_pano(crash_df, ball_tree, pano_df, threshold=25):\n",
    "    \"\"\"\n",
    "    Finds the nearest panoramic point to each crash point within a given threshold.\n",
    "    \"\"\"\n",
    "    crash_coords = np.radians(crash_df[['LAT', 'LON']].values)  # Convert to radians for latitude and longitude\n",
    "    distances, indices = ball_tree.query(crash_coords, k=1)  # Query nearest neighbor\n",
    "\n",
    "    # Convert distances from radians to meters (Earth's radius ~ 6371000 meters)\n",
    "    distances_meters = distances[:, 0] * 6371000\n",
    "\n",
    "    # Assign pano_id if within threshold\n",
    "    crash_df['matched_pano_id'] = [\n",
    "        pano_df.iloc[indices[i][0]]['pano_id'] if distances_meters[i] <= threshold else None\n",
    "        for i in range(len(distances_meters))\n",
    "    ]\n",
    "\n",
    "    return crash_df\n",
    "\n",
    "def get_car_crashes_with_panaramics():\n",
    "    simple_name = \"fredericksburg\"\n",
    "    base_directory = f\"data/{simple_name}\"\n",
    "\n",
    "    # Load datasets\n",
    "    panoramic_dataset = pd.read_csv(f\"{base_directory}/{simple_name}_panoramic_data.csv\")\n",
    "    crash_dataset = pd.read_csv(f\"{base_directory}/car_crashes_{simple_name}.csv\")\n",
    "\n",
    "    # Check the column names of the panoramic dataset\n",
    "    print(panoramic_dataset.columns)  # Debug: Check actual column names\n",
    "\n",
    "    # Assuming the columns are different, adjust based on the output.\n",
    "    # If the actual names are 'lat' and 'long', modify the following line:\n",
    "    pano_coords = np.radians(panoramic_dataset[['lat', 'long']].values)  # Adjust based on your column names\n",
    "\n",
    "    # Build the BallTree\n",
    "    ball_tree = BallTree(pano_coords, metric='haversine')\n",
    "    # Match crash points to panoramic points\n",
    "    result_df = find_nearest_pano(crash_dataset, ball_tree, panoramic_dataset, threshold=25)\n",
    "\n",
    "    # Display the result for verification\n",
    "    print(result_df.head())\n",
    "\n",
    "    # Remove rows where matched_pano_id is None\n",
    "    result_df = result_df.dropna(subset=['matched_pano_id'])\n",
    "\n",
    "    # Save the result to a new CSV file\n",
    "    result_df.to_csv(f\"{base_directory}/car_crashes_with_panoramics_{simple_name}.csv\", index=False)\n",
    "\n",
    "# Call the function to execute\n",
    "get_car_crashes_with_panaramics()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.distance import geodesic\n",
    "import math\n",
    "import osmnx as ox\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from shapely.geometry import Point\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point, LineString\n",
    "import import_ipynb\n",
    "import SunGlareDetection \n",
    "import ast\n",
    "from datetime import datetime, timedelta, timezone\n",
    "import folium\n",
    "\n",
    "\n",
    "def convert_military_integer_to_time(military_int):\n",
    "    # Ensure the military integer is a string with leading zeros if necessary\n",
    "    military_time = str(military_int).zfill(4)\n",
    "\n",
    "    # Extract hours and minutes\n",
    "    hours = int(military_time[:len(military_time)-2]) if len(military_time) > 2 else 0\n",
    "    minutes = int(military_time[len(military_time)-2:])\n",
    "\n",
    "    # Return formatted time\n",
    "    return hours,minutes\n",
    "\n",
    "def calculate_sun_glare_for_crashes(location):\n",
    "    simple_name = location.split(\",\")[0]\n",
    "    base_directory = f\"data/{simple_name}\"\n",
    "    output_crash_path = f\"{base_directory}/car_crashes_with_sun_glare_{simple_name}.csv\"\n",
    "    graph = ox.graph_from_place(location, network_type=\"drive\")\n",
    "\n",
    "    # Load the crash data\n",
    "    crash_data = pd.read_csv(f\"{base_directory}/car_crashes_with_panoramics_{simple_name}.csv\")\n",
    "    panoramic_data = pd.read_csv(f\"{base_directory}/{simple_name}_panoramic_data.csv\")\n",
    "    panoramic_data['segment_headings'] = panoramic_data['segment_headings'].apply(ast.literal_eval)\n",
    "\n",
    "    car_crashes_with_sun_glare = []\n",
    "\n",
    "    # iterate to find the sun glare for each crash\n",
    "    for index, row in crash_data.iterrows():\n",
    "        print(f\"==={index}===\")\n",
    "        print(f\"    matched_pano_id: {row['matched_pano_id']}\")\n",
    "        # Get the crash coordinates\n",
    "        lat, long = row['LAT'], row['LON']\n",
    "        car_crash_date = row['Crash Date']\n",
    "        month, day, year = car_crash_date.split(\"/\")\n",
    "        hour, minutes = convert_military_integer_to_time(row['Crash Military Time'])\n",
    "        print(f\"    {int(month)}/{day}/{year} {hour}:{minutes}\")\n",
    "        date_time = datetime(int(year), int(month), int(day), int(hour), int(minutes), 0, tzinfo=timezone.utc)\n",
    "        segmentation_dataset_path = f\"{base_directory}/{simple_name}_panoramic_imgs/panoramic_segmentation_maps\"\n",
    "     \n",
    "        matched_pano_id = row['matched_pano_id']\n",
    "        panoramic_img_path = f\"{base_directory}/{simple_name}_panoramic_imgs/panoramic_imgs/{matched_pano_id}.jpg\"\n",
    "        print(f\"    panoramic_img_path: {panoramic_img_path}\")\n",
    "        panoramic_row = panoramic_data[matched_pano_id == panoramic_data['pano_id']].iloc[0]\n",
    "        # print(f\"{panoramic_row['segment_headings'][0]}\")\n",
    "        # print(f\"    panoramic_row: {panoramic_row}\")\n",
    "        has_sun_glare = SunGlareDetection.check_if_any_sun_glare_at_panoramic_with_datetime(panoramic_row, date_time, segmentation_dataset_path, panoramic_img_path)\n",
    "        print(f\"    has_sun_glare: {has_sun_glare}\")\n",
    "\n",
    "        car_crashes_with_sun_glare.append({\n",
    "            'date_time': date_time,\n",
    "            'lat': lat,\n",
    "            'long': long,\n",
    "            'has_sun_glare': has_sun_glare\n",
    "        })\n",
    "\n",
    "    # save as csv\n",
    "    car_crashes_with_sun_glare_df = pd.DataFrame(car_crashes_with_sun_glare)\n",
    "    car_crashes_with_sun_glare_df.to_csv(output_crash_path, index=False)\n",
    "\n",
    "    # create map of accidents with sun glare\n",
    "    # Filter rows where has_sun_glare is True\n",
    "    sun_glare_data = car_crashes_with_sun_glare_df[car_crashes_with_sun_glare_df['has_sun_glare'] == True]\n",
    "\n",
    "\n",
    "    # Initialize the map with a default location (mean of latitudes and longitudes)\n",
    "    m = folium.Map(location=[sun_glare_data['lat'].mean(), sun_glare_data['long'].mean()], zoom_start=12)\n",
    "\n",
    "    # Add circles for locations with sun glare\n",
    "    for _, row in sun_glare_data.iterrows():\n",
    "        folium.Circle(\n",
    "            location=[row['lat'], row['long']],\n",
    "            radius=6,  # Radius in meters\n",
    "            color='red',\n",
    "            fill=True,\n",
    "            fill_opacity=0.6,\n",
    "            popup=f\"{lat},{long}\\nDate/Time: {row['date_time']}\"\n",
    "        ).add_to(m)\n",
    "    \n",
    "    # Save the map as an HTML file\n",
    "    m.save(f\"{base_directory}/car_crashes_with_sun_glare_map_{simple_name}.html\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    location = \"fredericksburg, VA, USA\"\n",
    "    calculate_sun_glare_for_crashes(location)\n",
    "\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
