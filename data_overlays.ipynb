{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description:\n",
    "\n",
    "- script for processing un-automated datasets to compare with the tool (such as car crashes and traffic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import osmnx as ox\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point, Polygon\n",
    "import geopandas as gpd\n",
    "import os\n",
    "\n",
    "def filter_crashes_within_area(data_file, place_name, output_file):\n",
    "    \"\"\"\n",
    "    Reads crash data and saves entries located within the bounding area defined by osmnx's graph_from_place.\n",
    "\n",
    "    Parameters:\n",
    "        data_file (str): Path to the CSV file containing crash data.\n",
    "        place_name (str): The place name to create the bounding area (e.g., \"Fredericksburg, VA, USA\").\n",
    "        output_file (str): Path to save the filtered data.\n",
    "\n",
    "    Returns:\n",
    "        None: Saves the filtered data to a new CSV file.\n",
    "    \"\"\"\n",
    "\n",
    "      # 1. Load the graph and convert it into a GeoDataFrame (bounding area)\n",
    "    print(\"Loading graph for the specified place...\")\n",
    "    graph = ox.graph_from_place(place_name, network_type=\"drive\")\n",
    "    gdf_boundary = ox.geocode_to_gdf(place_name)\n",
    "    print(gdf_boundary)\n",
    "    \n",
    "    # 2. Read the crash dataset\n",
    "    print(\"Reading crash dataset...\")\n",
    "    df = pd.read_csv(data_file)\n",
    "\n",
    "    # Check if the required columns (LAT and LON) exist\n",
    "    if 'LAT' not in df.columns or 'LON' not in df.columns:\n",
    "        print(\"Error: LAT and LON columns are missing in the dataset.\")\n",
    "        return\n",
    "\n",
    "    # 3. Convert crash data to GeoDataFrame using LAT and LON\n",
    "    print(\"Converting crash data to GeoDataFrame...\")\n",
    "    df['geometry'] = df.apply(lambda row: Point(row['LON'], row['LAT']), axis=1)\n",
    "    gdf_crashes = gpd.GeoDataFrame(df, geometry='geometry', crs=\"EPSG:4326\")\n",
    "\n",
    "    # 4. Filter crashes that fall within the bounding area\n",
    "    print(\"Filtering crashes within the area...\")\n",
    "    gdf_crashes_within = gdf_crashes[gdf_crashes.within(gdf_boundary.unary_union)]\n",
    "\n",
    "    # 5. Save the filtered crashes to a new CSV file\n",
    "    print(f\"Saving filtered crashes to {output_file}...\")\n",
    "    gdf_crashes_within.drop(columns=['geometry'], inplace=True)  # Remove geometry column before saving\n",
    "    gdf_crashes_within.to_csv(output_file, index=False)\n",
    "\n",
    "    print(\"Process complete. Filtered data saved successfully.\")\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    place_name = \"fredericksburg, VA, USA\"\n",
    "    simple_place_name = place_name.split(\",\")[0]\n",
    "\n",
    "    os.makedirs(f\"data/{simple_place_name}\", exist_ok=True)\n",
    "\n",
    "    data_file = f\"data/{simple_place_name}/features (1).csv\"\n",
    "    output_file = f\"data/{simple_place_name}/car_crashes_{simple_place_name}.csv\"\n",
    "    filter_crashes_within_area(data_file, place_name, output_file)\n",
    "\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing Crashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import BallTree\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "def find_nearest_pano(crash_df, ball_tree, pano_df, threshold=25):\n",
    "    \"\"\"\n",
    "    Finds the nearest panoramic point to each crash point within a given threshold.\n",
    "    \"\"\"\n",
    "    crash_coords = np.radians(crash_df[['LAT', 'LON']].values)  # Convert to radians for latitude and longitude\n",
    "    distances, indices = ball_tree.query(crash_coords, k=1)  # Query nearest neighbor\n",
    "\n",
    "    # Convert distances from radians to meters (Earth's radius ~ 6371000 meters)\n",
    "    distances_meters = distances[:, 0] * 6371000\n",
    "\n",
    "    # Assign pano_id if within threshold\n",
    "    crash_df['matched_pano_id'] = [\n",
    "        pano_df.iloc[indices[i][0]]['pano_id'] if distances_meters[i] <= threshold else None\n",
    "        for i in range(len(distances_meters))\n",
    "    ]\n",
    "\n",
    "    return crash_df\n",
    "\n",
    "def get_car_crashes_with_panaramics():\n",
    "    simple_name = \"fredericksburg\"\n",
    "    base_directory = f\"data/{simple_name}\"\n",
    "\n",
    "    # Load datasets\n",
    "    panoramic_dataset = pd.read_csv(f\"{base_directory}/{simple_name}_panoramic_data.csv\")\n",
    "    crash_dataset = pd.read_csv(f\"{base_directory}/car_crashes_{simple_name}.csv\")\n",
    "\n",
    "    # Check the column names of the panoramic dataset\n",
    "    print(panoramic_dataset.columns)  # Debug: Check actual column names\n",
    "\n",
    "    # Assuming the columns are different, adjust based on the output.\n",
    "    # If the actual names are 'lat' and 'long', modify the following line:\n",
    "    pano_coords = np.radians(panoramic_dataset[['lat', 'long']].values)  # Adjust based on your column names\n",
    "\n",
    "    # Build the BallTree\n",
    "    ball_tree = BallTree(pano_coords, metric='haversine')\n",
    "    # Match crash points to panoramic points\n",
    "    result_df = find_nearest_pano(crash_dataset, ball_tree, panoramic_dataset, threshold=25)\n",
    "\n",
    "    # Display the result for verification\n",
    "    print(result_df.head())\n",
    "\n",
    "    # Remove rows where matched_pano_id is None\n",
    "    result_df = result_df.dropna(subset=['matched_pano_id'])\n",
    "\n",
    "    # Save the result to a new CSV file\n",
    "    result_df.to_csv(f\"{base_directory}/car_crashes_with_panoramics_{simple_name}.csv\", index=False)\n",
    "\n",
    "# Call the function to execute\n",
    "get_car_crashes_with_panaramics()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.distance import geodesic\n",
    "import math\n",
    "import osmnx as ox\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from shapely.geometry import Point\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point, LineString\n",
    "import import_ipynb\n",
    "import SunGlareDetection \n",
    "import ast\n",
    "from datetime import datetime, timedelta, timezone\n",
    "import folium\n",
    "\n",
    "\n",
    "def convert_military_integer_to_time(military_int):\n",
    "    # Ensure the military integer is a string with leading zeros if necessary\n",
    "    military_time = str(military_int).zfill(4)\n",
    "\n",
    "    # Extract hours and minutes\n",
    "    hours = int(military_time[:len(military_time)-2]) if len(military_time) > 2 else 0\n",
    "    minutes = int(military_time[len(military_time)-2:])\n",
    "\n",
    "    # Return formatted time\n",
    "    return hours,minutes\n",
    "\n",
    "def calculate_sun_glare_for_crashes(location):\n",
    "    simple_name = location.split(\",\")[0]\n",
    "    base_directory = f\"data/{simple_name}\"\n",
    "    output_crash_path = f\"{base_directory}/car_crashes_with_sun_glare_{simple_name}.csv\"\n",
    "    graph = ox.graph_from_place(location, network_type=\"drive\")\n",
    "\n",
    "    # Load the crash data\n",
    "    crash_data = pd.read_csv(f\"{base_directory}/car_crashes_with_panoramics_{simple_name}.csv\")\n",
    "    panoramic_data = pd.read_csv(f\"{base_directory}/{simple_name}_panoramic_data.csv\")\n",
    "    panoramic_data['segment_headings'] = panoramic_data['segment_headings'].apply(ast.literal_eval)\n",
    "\n",
    "    car_crashes_with_sun_glare = []\n",
    "\n",
    "    # iterate to find the sun glare for each crash\n",
    "    for index, row in crash_data.iterrows():\n",
    "        print(f\"==={index}===\")\n",
    "        print(f\"    matched_pano_id: {row['matched_pano_id']}\")\n",
    "        # Get the crash coordinates\n",
    "        lat, long = row['LAT'], row['LON']\n",
    "        car_crash_date = row['Crash Date']\n",
    "        month, day, year = car_crash_date.split(\"/\")\n",
    "        hour, minutes = convert_military_integer_to_time(row['Crash Military Time'])\n",
    "        print(f\"    {int(month)}/{day}/{year} {hour}:{minutes}\")\n",
    "        date_time = datetime(int(year), int(month), int(day), int(hour), int(minutes), 0, tzinfo=timezone.utc)\n",
    "        segmentation_dataset_path = f\"{base_directory}/{simple_name}_panoramic_imgs/panoramic_segmentation_maps\"\n",
    "     \n",
    "        matched_pano_id = row['matched_pano_id']\n",
    "        panoramic_img_path = f\"{base_directory}/{simple_name}_panoramic_imgs/panoramic_imgs/{matched_pano_id}.jpg\"\n",
    "        print(f\"    panoramic_img_path: {panoramic_img_path}\")\n",
    "        panoramic_row = panoramic_data[matched_pano_id == panoramic_data['pano_id']].iloc[0]\n",
    "        # print(f\"{panoramic_row['segment_headings'][0]}\")\n",
    "        # print(f\"    panoramic_row: {panoramic_row}\")\n",
    "        has_sun_glare = SunGlareDetection.check_if_any_sun_glare_at_panoramic_with_datetime(panoramic_row, date_time, segmentation_dataset_path, panoramic_img_path)\n",
    "        print(f\"    has_sun_glare: {has_sun_glare}\")\n",
    "\n",
    "        car_crashes_with_sun_glare.append({\n",
    "            'date_time': date_time,\n",
    "            'lat': lat,\n",
    "            'long': long,\n",
    "            'has_sun_glare': has_sun_glare\n",
    "        })\n",
    "\n",
    "    # save as csv\n",
    "    car_crashes_with_sun_glare_df = pd.DataFrame(car_crashes_with_sun_glare)\n",
    "    car_crashes_with_sun_glare_df.to_csv(output_crash_path, index=False)\n",
    "\n",
    "    # create map of accidents with sun glare\n",
    "    # Filter rows where has_sun_glare is True\n",
    "    sun_glare_data = car_crashes_with_sun_glare_df[car_crashes_with_sun_glare_df['has_sun_glare'] == True]\n",
    "\n",
    "\n",
    "    # Initialize the map with a default location (mean of latitudes and longitudes)\n",
    "    m = folium.Map(location=[sun_glare_data['lat'].mean(), sun_glare_data['long'].mean()], zoom_start=12)\n",
    "\n",
    "    # Add circles for locations with sun glare\n",
    "    for _, row in sun_glare_data.iterrows():\n",
    "        folium.Circle(\n",
    "            location=[row['lat'], row['long']],\n",
    "            radius=6,  # Radius in meters\n",
    "            color='red',\n",
    "            fill=True,\n",
    "            fill_opacity=0.6,\n",
    "            popup=f\"{lat},{long}\\nDate/Time: {row['date_time']}\"\n",
    "        ).add_to(m)\n",
    "    \n",
    "    # Save the map as an HTML file\n",
    "    m.save(f\"{base_directory}/car_crashes_with_sun_glare_map_{simple_name}.html\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    location = \"fredericksburg, VA, USA\"\n",
    "    calculate_sun_glare_for_crashes(location)\n",
    "\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
